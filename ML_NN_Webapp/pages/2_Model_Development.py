import streamlit as st

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="ML & NN Models Information", layout="wide")

# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
st.title("Model Development")
st.divider()
# ‡πÉ‡∏ä‡πâ st.radio ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
option = st.radio(
    "üîç **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:**",
    ("ü§ñ Machine Learning (ML)", "üß† Neural Network (NN)"),
    horizontal=True
)
st.divider()
if option == "ü§ñ Machine Learning (ML)":
        st.header("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ Machine Learning (ML)")
        st.write("1.‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô")
        st.code("""
        import import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        from google.colab import files, drive
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler, OneHotEncoder
        from sklearn.impute import SimpleImputer
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.cluster import KMeans
        from sklearn.decomposition import PCA
        import pickle
        import cloudpickle as cp
            """, language='python')
        st.write("2.‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Drive ‡∏Å‡∏±‡∏ö Google Colab ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive ‡∏à‡∏≤‡∏Å Colab ‡πÑ‡∏î‡πâ")
        st.code("""from google.colab import drive
drive.mount('/content/drive')""")
        st.write("3.‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Dataset ‡∏°‡∏≤‡∏à‡∏≤‡∏Å GitHub, ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 50 ‡πÅ‡∏ñ‡∏ß, ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Drive ‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
        st.code("""df = pd.read_csv('https://github.com/prasertcbs/tutorial/raw/master/msleep.csv')
df = df.sample(50, random_state=123)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Google Drive
file_path = '/content/drive/MyDrive/IS_Final_Project/ML_Model/DatasetML/msleep_sample.csv'

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å DataFrame ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏ô Google Drive
df.to_csv(file_path, index=False)

print(f"File saved to: {file_path}")""")
        st.write("4.‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö missing values ‡πÉ‡∏ô DataFrame")
        st.code("""print("Missing Values: ", df.isnull().sum())""")
        st.write("5.‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ missing values ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (num_cols) ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Mean) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ SimpleImputer ‡∏à‡∏≤‡∏Å‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ sklearn.impute")
        st.code("""num_cols = ['bodywt', 'brainwt', 'sleep_total', 'sleep_rem', 'sleep_cycle', 'awake']
imputer = SimpleImputer(strategy="mean")
df[num_cols] = imputer.fit_transform(df[num_cols])""")
        st.write("6.‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (categorical) ‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤ vore ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ One-Hot Encoding ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pd.get_dummies()")
        st.code("""cat_cols = ['vore'] if 'vore' in df.columns else []
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)""")
        st.write("7.‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏î‡πâ‡∏ß‡∏¢ Heatmap ‡∏ã‡∏∂‡πà‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÉ‡∏î‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")
        st.code("""plt.figure(figsize=(8, 6))
numeric_df = df.select_dtypes(include=np.number)
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show())""")
        st.write("8.‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ X (Features) ‡πÅ‡∏•‡∏∞ y (Target variable) ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì sleep_total")
        st.code("""X = df[['bodywt', 'brainwt', 'sleep_rem', 'sleep_cycle', 'awake']]
y = df['sleep_total']""")
        st.write("9.Scaling ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏ä‡πâ StandardScaler ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô 1) ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)""")
        st.write("10.‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å (train) ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö (test) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ train_test_split ‡∏à‡∏≤‡∏Å sklearn")
        st.code("""X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)""")
        st.write("11.‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression ‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å (X_train ‡πÅ‡∏•‡∏∞ y_train)")
        st.code("""lr_model = LinearRegression()
lr_model.fit(X_train, y_train)""")
        st.write("12.‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö (X_test ‡πÅ‡∏•‡∏∞ y_test) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Mean Squared Error (MSE) ‡πÅ‡∏•‡∏∞ R¬≤ Score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""#  Evaluate Model
y_pred = lr_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"üìä Mean Squared Error (MSE): {mse:.4f}")
print(f"üìà R¬≤ Score (Test Data): {r2:.4f}")

#  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Overfitting
train_r2 = lr_model.score(X_train, y_train)
test_r2 = lr_model.score(X_test, y_test)

print(f"üü¢ Train R¬≤: {train_r2:.4f}")
print(f"üîµ Test R¬≤: {test_r2:.4f}")
""")
        st.write("13.‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü ‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á vs ‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ scatter plot ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á (y_test) ‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (y_pred) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡πâ‡∏ô ideal line ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""#  ‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue', label='Predictions', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Ideal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs Predicted Values')
plt.legend()
plt.grid(True)
plt.show()""")
        st.write("14.‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ scaler ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pickle ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á")
        st.code("""
    model_path = '/content/drive/MyDrive/IS_Final_Project/ML_Model/linear_regression_model.sav'
    scaler_path = '/content/drive/MyDrive/IS_Final_Project/ML_Model/scaler.sav'
    pickle.dump(lr_model, open(model_path, 'wb'))
    pickle.dump(scaler, open(scaler_path, 'wb'))

    # Load using pickle
    loaded_lr_model = pickle.load(open(model_path, 'rb'))
    loaded_scaler = pickle.load(open(scaler_path, 'rb'))""")
        st.write("15.‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ‡∏Ñ‡πà‡∏≤ R¬≤ (R-squared) ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""result = loaded_lr_model.score(X_test, y_test)
    print(f"Model Accuracy (R¬≤ score): {result:.4f}")""")
        st.write("16.‡πÉ‡∏ä‡πâ Elbow Method ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° (K) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö K-Means clustering ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WCSS")
        st.code("""wcss = []
    for k in range(1, 11):
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(X_scaled)
        wcss.append(kmeans.inertia_)

    plt.figure(figsize=(8, 5))
    plt.plot(range(1, 11), wcss, marker="o", linestyle="--")
    plt.xlabel("Number of Clusters (K)")
    plt.ylabel("WCSS")
    plt.title("Elbow Method for Optimal K")
    plt.show()""")
        st.write("17.‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• K-Means Clustering ‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î (scaled data) ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏±‡∏™‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (K=3)")
        st.code("""optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)""")
        st.write("18.‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å K-Means Model ‡∏î‡πâ‡∏ß‡∏¢ pickle")
        st.code("""kmeans_model_path = '/content/drive/MyDrive/IS_Final_Project/ML_Model/kmeans_model.sav'  # Use the Google Drive path here
pickle.dump(kmeans, open(kmeans_model_path, 'wb'))""")
        st.write("19.‡πÇ‡∏´‡∏•‡∏î K-Means Model ‡∏à‡∏≤‡∏Å Google Drive")
        st.code("""kmeans_model_path = '/content/drive/MyDrive/IS_Final_Project/ML_Model/kmeans_model.sav'
loaded_kmeans_model = cp.load(open(kmeans_model_path, 'rb'))""")
        st.write("20.PCA ‡∏•‡∏î‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô 2D ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü Clustering")
        st.code("""pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap="viridis", edgecolors="k")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("K-Means Clustering Visualization")
plt.colorbar(label="Cluster")
plt.show()""")
        st.write("21.‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ")
        st.code("""files.download("/content/drive/MyDrive/IS_Final_Project/ML_Model/linear_regression_model.sav")
files.download("/content/drive/MyDrive/IS_Final_Project/ML_Model/scaler.sav") 
files.download("/content/drive/MyDrive/IS_Final_Project/ML_Model/kmeans_model.sav") """)

elif option == "üß† Neural Network (NN)":
        st.header("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ Neural Network (NN)")
        st.write("1.‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô")
        st.code("""import numpy as np
import random
import pickle
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
""")
        st.write("2.‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Drive ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive ‡∏à‡∏≤‡∏Å Colab ‡πÑ‡∏î‡πâ")
        st.code("""from google.colab import drive
drive.mount('/content/drive')""")
        st.write("3.‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Dataset ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ np.loadtxt() ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° X_train, Y_train, X_test, Y_test ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""#  2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå 
input_path = "/content/drive/MyDrive/IS_Final_Project/NN_Model/DatasetNN/input.csv"
labels_path = "/content/drive/MyDrive/IS_Final_Project/NN_Model/DatasetNN/labels.csv"
input_test_path = "/content/drive/MyDrive/IS_Final_Project/NN_Model/DatasetNN/input_test.csv"
labels_test_path = "/content/drive/MyDrive/IS_Final_Project/NN_Model/DatasetNN/labels_test.csv"

#  3. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ CSV ‡πÑ‡∏°‡πà‡∏°‡∏µ header ‡∏´‡∏£‡∏∑‡∏≠ string)
X_train = np.loadtxt(input_path, delimiter=',')
Y_train = np.loadtxt(labels_path, delimiter=',')

X_test = np.loadtxt(input_test_path, delimiter=',')
Y_test = np.loadtxt(labels_test_path, delimiter=',')

""")
        st.write("4.Reshape ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏õ‡∏£‡∏±‡∏ö X_train ‡πÅ‡∏•‡∏∞ X_test ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 100√ó100√ó3 (RGB) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö CNN ‡πÅ‡∏•‡∏∞ Normalize ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0,1] ‡πÇ‡∏î‡∏¢‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 255.0 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ")
        st.code("""#  Reshape ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö CNN Input (100x100x3)
X_train = X_train.reshape(-1, 100, 100, 3)
Y_train = Y_train.reshape(-1, 1)
X_test = X_test.reshape(-1, 100, 100, 3)
Y_test = Y_test.reshape(-1, 1)

#  Normalize ‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, 1]
X_train = X_train / 255.0
X_test = X_test / 255.0""")
        st.write("5.‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.code("""print("Shape of X_train ", X_train.shape)
print("Shape of Y_train ", Y_train.shape)
print("Shape of X_test ", X_test.shape)
print("Shape of Y_test ", Y_test.shape)""")
        st.write("6.‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Dataset ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å X_train ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ plt.imshow() ‡∏û‡∏£‡πâ‡∏≠‡∏° label ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û")
        st.code("""idx = random.randint(0, len(X_train) - 1)
plt.imshow(X_train[idx])
plt.title(f"Example Image - Label: {Y_train[idx][0]}")
plt.show()""")
        st.write("7.‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡∏î‡πâ‡∏ß‡∏¢ Sequential() ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Binary Classification (‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û ‡∏´‡∏°‡∏≤ vs ‡πÅ‡∏°‡∏ß)")
        with st.expander("üìå **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**"):
            st.write("""
            - **Conv2D(32, 3√ó3) + ReLU**  ‡∏î‡∏∂‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û
            - **MaxPooling2D(2√ó2)** ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏û
            - **Conv2D(64, 3√ó3) + ReLU** ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
            - **MaxPooling2D(2√ó2)** ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏û‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            - **Flatten()** ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå
            - **Dense(128) + ReLU** Fully Connected Layer
            - **Dense(1) + Sigmoid** ‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡πÅ‡∏ö‡∏ö 0 ‡∏´‡∏£‡∏∑‡∏≠ 1 (Binary Classification) 
            """)
        st.code("""model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)),
    MaxPooling2D((2,2)),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # Binary Classification (Dog vs Cat)
])""")
        st.write("8.‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå ‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Binary Classification ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Conv2D ‡πÅ‡∏•‡∏∞ MaxPooling2D ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ Dense ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏´‡∏£‡∏∑‡∏≠ 1 (‡∏´‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡πÅ‡∏°‡∏ß) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ binary_crossentropy ‡πÄ‡∏õ‡πá‡∏ô loss function ‡πÅ‡∏•‡∏∞ adam optimizer ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ß‡∏±‡∏î accuracy ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        st.code("""model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])""")
        st.write("9.‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏î‡πâ‡∏ß‡∏¢ model.fit() ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ history ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á")
        st.code("""history = model.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test))""")
        st.write("10.‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .sav ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pickle.dump() ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Google Drive ‡∏ó‡∏µ‡πàpath‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
        st.code("""model_path = "/content/drive/MyDrive/IS_Final_Project/NN_Model/finalized_model.sav"
pickle.dump(model, open(model_path, 'wb'))
print(f"‚úÖ Model saved at: {model_path}")""")
        st.write("11.‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .sav ‡∏î‡πâ‡∏ß‡∏¢ pickle.load()")
        st.code("""loaded_model = pickle.load(open(model_path, 'rb'))
print("‚úÖ Model Loaded Successfully!")""")
        st.write("12.‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ evaluate() ‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö (X_test, Y_test) ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á ‡∏Ñ‡πà‡∏≤ Loss ‡πÅ‡∏•‡∏∞ Accuracy ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
        st.code("""loss, acc = loaded_model.evaluate(X_test, Y_test)
print(f"Test Accuracy: {acc:.4f}")
print(f"Test Loss: {loss:.4f}")""")
        st.write("13.‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å X_test ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏´‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡πÅ‡∏°‡∏ß ‡πÇ‡∏î‡∏¢‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô Dog ‡∏´‡∏£‡∏∑‡∏≠ Cat")
        st.code("""#  Making Predictions
idx2 = random.randint(0, len(Y_test) - 1)
plt.imshow(X_test[idx2])
plt.title("Random Test Image")
plt.show()

y_pred = loaded_model.predict(X_test[idx2].reshape(1, 100, 100, 3))
y_pred = y_pred > 0.5

# Print ‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
pred_class = "Dog" if y_pred[0][0] == 0 else "Cat"
print(f"Our model predicts it is a: {pred_class}")""")
        st.write("14.‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å X_test ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô 0 (‡∏´‡∏°‡∏≤) ‡∏´‡∏£‡∏∑‡∏≠ 1 (‡πÅ‡∏°‡∏ß) ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ classification_report() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏£‡πâ‡∏≠‡∏° precision, recall, f1-score ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™")
        st.code(""""y_pred_all = loaded_model.predict(X_test)
y_pred_classes = (y_pred_all > 0.5).astype(int)
print(classification_report(Y_test, y_pred_classes, target_names=['Dog', 'Cat']))""")
        st.write("15.‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Confusion Matrix ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô heatmap ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ sns.heatmap() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted) ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á (Actual) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ‡∏´‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏°‡∏ß")
        st.code("""cm = confusion_matrix(Y_test, y_pred_classes)
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Dog', 'Cat'], yticklabels=['Dog', 'Cat'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()""")
        st.write("16.‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        with st.expander("üìå **‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•**"):
            st.write("""
            - **‡∏Å‡∏£‡∏≤‡∏ü Accuracy**  ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö (validation)
            - **‡∏Å‡∏£‡∏≤‡∏ü Loss** ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö (validation) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ plt.subplot() ‡πÅ‡∏•‡∏∞ history ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô.
            """)
        st.code("""plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Model Accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Model Loss')

plt.show()""")
st.sidebar.markdown(
    """
    <style>
    .sidebar-footer {
        position: absolute;
        width: 100%;
        text-align: center;
    }
    .sidebar-footer a {
        font-size: 16px;
        color: white;
        text-decoration: none;
    }
    .sidebar-footer img {
        vertical-align: middle;
        margin-right: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Add GitHub link at the bottom of the sidebar
st.sidebar.markdown(
    """
    <div class="sidebar-footer">
        <a href="https://github.com/PichchakornK/ISProject.git" target="_blank">
            <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" width="20" height="20">
            6404062663215 Pichchakorn Kongmai
        </a>
    </div>
    """,
    unsafe_allow_html=True
)

# Reference section in the sidebar with improved styling
st.sidebar.markdown(
    """
    <div class="sidebar-footer" style="margin-top: 20px; padding: 10px; background-color: rgba(0, 0, 0, 0.5); border-radius: 10px;">
        <h3 style="color:white; text-align:center; margin-bottom: 15px;">üìö References</h3>
        <div style="margin-bottom: 10px;">
            <p style="color:white; font-size: 14px;">Dataset for ML: 
                <a href="https://raw.githubusercontent.com/prasertcbs/tutorial/master/msleep.csv" target="_blank" style="color: #3498db; text-decoration: none;">ML Dataset Link</a>
            </p>
        </div>
        <div style="margin-bottom: 10px;">
            <p style="color:white; font-size: 14px;">Dataset for NN: 
                <a href="https://drive.google.com/drive/u/0/folders/1dZvL1gi5QLwOGrfdn9XEsi4EnXx535bD" target="_blank" style="color: #3498db; text-decoration: none;">NN Dataset Link</a>
            </p>
        </div>
        <div style="margin-bottom: 10px;">
            <p style="color:white; font-size: 14px;">Machine Learning Tutorial: 
                <a href="https://www.youtube.com/watch?v=T2yT5vt1NaQ&list=PLoTScYm9O0GH_3VrwwnQafwWQ6ibKnEtU&index=6" target="_blank" style="color: #3498db; text-decoration: none;">ML Video Link</a>
            </p>
        </div>
        <div style="margin-bottom: 10px;">
            <p style="color:white; font-size: 14px;">Neural Network Tutorial: 
                <a href="https://github.com/Coding-Lane/Image-Classification-CNN-Keras.git" target="_blank" style="color: #3498db; text-decoration: none;">NN GitHub Link</a>
            </p>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)
